{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfJ-634MTThq"
      },
      "source": [
        "# For Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-_yfyqfTGL0",
        "outputId": "501f019b-4c36-40e8-9bb4-af7204f19313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQB7dLcd4Shf"
      },
      "source": [
        "# Import Packages :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkYkoNZBPOUe"
      },
      "outputs": [],
      "source": [
        "# basic stuffs\n",
        "import csv\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import math\n",
        "import random as rand\n",
        "from typing import Dict\n",
        "\n",
        "# other library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualization tools\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data \n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrhD1L5pIDwM"
      },
      "source": [
        "# Fix Randomization Seed :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt4o2839PzQO"
      },
      "outputs": [],
      "source": [
        "SEED = 42 # Do not modify\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "rand.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWdfr4FIINxK"
      },
      "source": [
        "#Parameters :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iarwZrESAajW"
      },
      "outputs": [],
      "source": [
        "TIME_FRAME_SIZE = 5\n",
        "\n",
        "#setting\n",
        "pd.set_option('precision', 4)\n",
        "pd.set_option(\"display.max_columns\",100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXyQQ8aA4LHy"
      },
      "source": [
        "# load data from google cloud :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd_5pp0d1ZA3"
      },
      "outputs": [],
      "source": [
        "# Youchen datapath\n",
        "\n",
        "# ccba = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/ccba.csv')\n",
        "# custinfo = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/custinfo.csv')\n",
        "\n",
        "# cdtx = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/cdtx.csv')\n",
        "# dp = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/dp.csv')\n",
        "# remit1 = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/remit.csv')\n",
        "\n",
        "train_alert_date = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/train_x_alert_date.csv')\n",
        "y = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/train_y_answer.csv')\n",
        "\n",
        "training_data = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/1215/training_data_complete_5.csv')\n",
        "training_label = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/1215/training_data_labels_5.csv')\n",
        "\n",
        "testing_data = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/1215/testing_data_complete_5.csv')\n",
        "testing_key = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/1215/testing_alert_key_5.csv')\n",
        "\n",
        "sample_output = pd.read_csv('/content/gdrive/MyDrive/Fintech_final/sample_output.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VphSoFGT6mOp"
      },
      "source": [
        "# Perform Onehot Pooling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHLcW2qbQM4M"
      },
      "outputs": [],
      "source": [
        "# Drop columns\n",
        "drop_cols = ['Unnamed: 0', \n",
        "      'remit_transtime_diff_1',\t\n",
        "      'remit_transtime_diff_2',\t\n",
        "      'remit_transtime_diff_3',\t\n",
        "      'remit_transtime_diff_4',\t\n",
        "      'remit_transtime_diff_5',\t\n",
        "      'remit_transtime_avg'\n",
        "      ]\n",
        "      \n",
        "train = training_data.drop(columns=drop_cols)\n",
        "test = testing_data.drop(columns=drop_cols)\n",
        "\n",
        "train_label = training_label.drop(columns='Unnamed: 0')\n",
        "test_keys = testing_key.drop(columns='Unnamed: 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqpJpwxPTtBY"
      },
      "outputs": [],
      "source": [
        "# Determine categorical column names\n",
        "cat_cols = ['occupation_code',\n",
        "       'country_1', 'cur_type_1',\n",
        "       'country_2', 'cur_type_2',\n",
        "       'country_3', 'cur_type_3',\n",
        "       'country_4', 'cur_type_4',\n",
        "       'country_5', 'cur_type_5',\n",
        "       'debit_credit_1', 'tx_type_1', 'info_asset_code_1', 'fiscTxId_1', 'txbranch_1', 'cross_bank_1', 'ATM_1',\n",
        "       'debit_credit_2', 'tx_type_2', 'info_asset_code_2', 'fiscTxId_2', 'txbranch_2', 'cross_bank_2', 'ATM_2',\n",
        "       'debit_credit_3', 'tx_type_3', 'info_asset_code_3', 'fiscTxId_3', 'txbranch_3', 'cross_bank_3', 'ATM_3',\n",
        "       'debit_credit_4', 'tx_type_4', 'info_asset_code_4', 'fiscTxId_4', 'txbranch_4', 'cross_bank_4', 'ATM_4',\n",
        "       'debit_credit_5', 'tx_type_5', 'info_asset_code_5', 'fiscTxId_5', 'txbranch_5', 'cross_bank_5', 'ATM_5',\n",
        "       'trans_no_1', 'trans_no_2', 'trans_no_3', 'trans_no_4', 'trans_no_5'\n",
        "       ]\n",
        "\n",
        "# Determine pooling column names\n",
        "pool_cols = ['country', 'cur_type', 'debit_credit', 'tx_type', 'info_asset_code',\n",
        "        'fiscTxId', 'txbranch', 'cross_bank', 'ATM', 'trans_no']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZpR3-uwVsS7"
      },
      "outputs": [],
      "source": [
        "# Get train/test onehot\n",
        "train[cat_cols] = train[cat_cols].astype(int)\n",
        "train_onehot = pd.get_dummies(train, columns=cat_cols)\n",
        "\n",
        "test[cat_cols] = test[cat_cols].astype(int)\n",
        "test_onehot = pd.get_dummies(test, columns=cat_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAewYy_qXhGB"
      },
      "outputs": [],
      "source": [
        "# Get existing onehot keys -> count\n",
        "#  'debit_credit': [0, 1],\n",
        "#  'tx_type': [1, 2, 3]\n",
        "count = {}\n",
        "for pool in pool_cols:\n",
        "  first = True\n",
        "  for c in train.columns:\n",
        "    if pool in c:\n",
        "      index = train[c].value_counts().index\n",
        "      if first:\n",
        "        count[pool] = []\n",
        "        for i in range(len(index)):\n",
        "          count[pool].append(index[i])\n",
        "        first = False\n",
        "      else:\n",
        "        for i in range(len(index)):\n",
        "          if index[i] not in count[pool]:\n",
        "            count[pool].append(index[i])\n",
        "  count[pool] = sorted(count[pool])\n",
        "# count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxyCnjBwTP3t"
      },
      "outputs": [],
      "source": [
        "# Training set Pooling\n",
        "train_col_names = []\n",
        "train_col_datas = []\n",
        "for key in count.keys():\n",
        "  for value in count[key]:\n",
        "    temp = None\n",
        "    temp_name = key+'_'+str(value)\n",
        "    for i in range(1, 6):\n",
        "      col_name = key+'_'+str(i)+'_'+str(value)\n",
        "      # if col_name not in train_onehot.columns:\n",
        "      #   continue\n",
        "      try:\n",
        "        if temp is None:\n",
        "          temp = train_onehot[col_name].copy()\n",
        "        else:\n",
        "          temp += train_onehot[col_name].copy()\n",
        "      except:\n",
        "        pass\n",
        "    if temp is not None:\n",
        "      train_col_datas.append(temp.to_numpy())\n",
        "    else:\n",
        "      train_col_datas.append(np.zeros(len(test)))\n",
        "    train_col_names.append(temp_name)\n",
        "\n",
        "# temp.to_numpy()\n",
        "# temp_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHOKnZWkztT0"
      },
      "outputs": [],
      "source": [
        "# Testing set Pooling\n",
        "test_col_names = []\n",
        "test_col_datas = []\n",
        "for key in count.keys():\n",
        "  for value in count[key]:\n",
        "    temp = None\n",
        "    temp_name = key+'_'+str(value)\n",
        "    for i in range(1, 6):\n",
        "      col_name = key+'_'+str(i)+'_'+str(value)\n",
        "      # if col_name not in train_onehot.columns:\n",
        "      #   continue\n",
        "      try:\n",
        "        if temp is None:\n",
        "          temp = test_onehot[col_name].copy()\n",
        "        else:\n",
        "          temp += test_onehot[col_name].copy()\n",
        "      except:\n",
        "        pass\n",
        "    if temp is not None:\n",
        "      test_col_datas.append(temp.to_numpy())\n",
        "    else:\n",
        "      test_col_datas.append(np.zeros(len(test)).astype(int))\n",
        "    test_col_names.append(temp_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HjF-a0As6q8"
      },
      "outputs": [],
      "source": [
        "# Categorical features\n",
        "all_cat = pd.DataFrame(np.array(train_col_datas).T, columns=train_col_names)\n",
        "test_cat = pd.DataFrame(np.array(test_col_datas).T, columns=test_col_names)\n",
        "\n",
        "# Numerical features\n",
        "all_num = train.drop(columns=cat_cols)\n",
        "test_num = test.drop(columns=cat_cols)\n",
        "\n",
        "# To ensure same dim when rerunning\n",
        "all_label = training_label.drop(columns='Unnamed: 0')\n",
        "\n",
        "# Train/val split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_cat, val_cat, train_num, val_num, train_label, val_label \\\n",
        "      = train_test_split(all_cat, all_num, all_label, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph_7FGTO1zsH"
      },
      "outputs": [],
      "source": [
        "# Normalization of numerical feats\n",
        "def normalize(X, preMax=None, preMin=None, is_train=True):\n",
        "  if is_train:\n",
        "    Max = X.max()\n",
        "    Min = X.min()\n",
        "    X_norm = (X - Min) / (Max - Min)\n",
        "    \n",
        "    return X_norm, Max, Min\n",
        "  else:\n",
        "    X_norm = (X - preMin) / (preMax - preMin)\n",
        "    \n",
        "    return X_norm, preMax, preMin\n",
        "\n",
        "train_num_norm, train_max, train_min = normalize(train_num, is_train=True)\n",
        "val_num_norm, _, _ = normalize(val_num, preMax=train_max, preMin = train_min, is_train=False)\n",
        "test_num_norm, _, _ = normalize(test_num, preMax=train_max, preMin = train_min, is_train=False)\n",
        "\n",
        "all_num_norm, _, _ = normalize(all_num, is_train=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjQ6sG1g5ijU"
      },
      "outputs": [],
      "source": [
        "train_set = pd.merge(train_cat.reset_index(), train_num_norm.reset_index()).drop(columns='index')\n",
        "val_set = pd.merge(val_cat.reset_index(), val_num_norm.reset_index()).drop(columns='index')\n",
        "test_set = pd.merge(test_cat.reset_index(), test_num_norm.reset_index()).drop(columns='index')\n",
        "\n",
        "all_set = pd.merge(all_cat.reset_index(), all_num_norm.reset_index()).drop(columns='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k2BpcuGLaIg"
      },
      "source": [
        "# Resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVdw-m3HLZg8",
        "outputId": "cdeb60f9-5713-46a5-ff06-ccf3418b39b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0    18948\n",
              "1.0      176\n",
              "Name: labels, dtype: int64"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x_y = pd.concat([train, train_label], axis=1)\n",
        "train_x_y['labels'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i45Kk_fDNez_"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "def resampling(data, y_col, ratio='100_100'):\n",
        "  ##################################################\n",
        "  #  data: target DataFrame          #\n",
        "  #  y_col: the name of y column     　#\n",
        "  #  ratio: expected ratio of two classes .#\n",
        "  ##################################################\n",
        "  # String process\n",
        "  [ratio_0, ratio_1] = ratio.split('_')\n",
        "  ratio_0, ratio_1 = int(ratio_0), int(ratio_1)\n",
        "  num_0, num_1 = data[y_col].value_counts()\n",
        "  \n",
        "  # Initialization\n",
        "  n_samples = [0, 0]\n",
        "  group = {}\n",
        "\n",
        "  # Num of samples of class 0/1\n",
        "  # (Switch n_samples values if minor class is 0)\n",
        "  max_n = max(num_0, num_1)    # Bigger number of sample\n",
        "  seg = max_n // 100       # Cut this number into 100 pieces\n",
        "  n_samples[0] = num_0 if ratio_0 == 100 \\\n",
        "              else seg * ratio_0  # Use all samples if ratio_0 == 100, downsample if not\n",
        "  n_samples[1] = seg * ratio_1  # Oversampling of minor class\n",
        "  \n",
        "  # Resample\n",
        "  for i in [0, 1]:\n",
        "    g = data[data[y_col] == i]\n",
        "    group[str(i)] = resample(g, replace=True, n_samples=n_samples[i])\n",
        "\n",
        "  # Concat two class into a DataFrame\n",
        "  # (Shuffle as you wish)\n",
        "  up = pd.concat(group.values())\n",
        "\n",
        "  return up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4I6RD7mnx3l"
      },
      "source": [
        "# Youchen Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdrXBLgrRUE0"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JufOYZ3CQLjV"
      },
      "outputs": [],
      "source": [
        "# upsampled_data = resampling(train_set, 'labels', ratio='70_50')\n",
        "# upsampled_data['labels'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtNsQ5XABWI6",
        "outputId": "7f109f31-99cc-47cd-fb65-0540f4ffadd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost==1.7.2 in /usr/local/lib/python3.8/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost==1.7.2) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost==1.7.2) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost==1.7.2\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvreEq8M3c31"
      },
      "outputs": [],
      "source": [
        "# Reassign if resampled\n",
        "# train_set = upsampled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCjiBlDvqexM"
      },
      "outputs": [],
      "source": [
        "train_X, train_y = train_set, train_label\n",
        "val_X, val_y = val_set, val_label\n",
        "\n",
        "all_X, all_y = all_set, all_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq44hkF9RQiD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puAL-5BwRSZz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TohefFcQsHPD"
      },
      "outputs": [],
      "source": [
        "def recall_n(output, target):\n",
        "    comb = list(zip(output, target))\n",
        "    comb.sort(key=lambda x:x[0])\n",
        "    flag = False\n",
        "    for i, (out, gt) in enumerate(comb):\n",
        "        if gt == 1:\n",
        "            if flag:\n",
        "                break\n",
        "            flag = True\n",
        "    \n",
        "    return (sum(target)-1) / (len(target)-i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DTP873kBfjz"
      },
      "outputs": [],
      "source": [
        "# XGBoost\n",
        "\n",
        "xgbModel = xgb.XGBClassifier(max_delta_step=1, random_state=0)\n",
        "xgbModel.fit(train_X, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niZJY-tUGHWe"
      },
      "outputs": [],
      "source": [
        "# XGBoost predict\n",
        "\n",
        "# test = xgbModel.predict(val_X)\n",
        "val_pred = xgbModel.predict_proba(val_X)\n",
        "# train_pred = xgbModel.predict_proba(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF01hxO5GOXH",
        "outputId": "21afa874-4fb5-437b-ea25-f4f96a5c5a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.01536388]\n"
          ]
        }
      ],
      "source": [
        "print(recall_n(val_pred[:, 1].reshape(-1, 1), val_y.to_numpy()))\n",
        "# val_pred[:, 1].reshape(-1, 1)\n",
        "# val_y.shape\n",
        "# print(val_y.to_numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQpwb4LHTvmQ"
      },
      "outputs": [],
      "source": [
        "# XGBoost grid search\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "7LJ7DI5bT9YC",
        "outputId": "71f39a35-3766-4512-f524-24ff0aa2d413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-362-43a15f106c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m random_search = RandomizedSearchCV(xgbModel, param_distributions=params, n_iter=param_comb, scoring='recall',\n\u001b[1;32m     11\u001b[0m                   n_jobs=4, cv=skf.split(all_X, all_y), verbose=3, random_state=42)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[1;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "xgbModel = xgb.XGBClassifier(learning_rate=0.02, n_estimators=600, \n",
        "                objective='binary:logistic', silent=True, nthread=1)\n",
        "\n",
        "param_comb = 5\n",
        "folds = 5\n",
        "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 42)\n",
        "random_search = RandomizedSearchCV(xgbModel, param_distributions=params, n_iter=param_comb, scoring='recall',\n",
        "                  n_jobs=4, cv=skf.split(all_X, all_y), verbose=3, random_state=42)\n",
        "random_search.fit(all_X, all_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3fFKj7mYkie",
        "outputId": "6676b6f3-4f9e-4d00-d657-09f5edb48a44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.021367521367521364"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5D3XHRL6Gom",
        "outputId": "f82543b2-9d4a-47b1-e2b1-b2eab0942a80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([352342, 352866, 352696, ..., 364673, 364626, 364986])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_keys['alert_key'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DGxOVYpym1i",
        "outputId": "f1895d87-da9d-4482-a14d-67992a08387c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[358457, 0.39968827], [356628, 0.32680205], [361303, 0.28409693], [358988, 0.24368204], [358229, 0.24151605], [358005, 0.20350923], [361145, 0.15852714], [355403, 0.12102158], [355801, 0.1100383], [364628, 0.100587085], [356249, 0.09423577], [359785, 0.09423577], [362488, 0.09267317], [364673, 0.09059842], [355198, 0.088532686], [358721, 0.087355345], [362127, 0.0866188], [359499, 0.08656027], [363738, 0.08269125], [360601, 0.08065418], [355795, 0.07054985], [363033, 0.06937326], [364699, 0.067987196], [364223, 0.06753303], [353413, 0.06701272], [364033, 0.06602663], [357108, 0.063868135], [358252, 0.06047292], [361118, 0.060414225], [355436, 0.05628564], [353084, 0.056184895], [360534, 0.053050563], [355810, 0.052848704], [364698, 0.052553874], [353566, 0.051309414], [357098, 0.051035628], [359384, 0.050216094], [364626, 0.048046365], [355633, 0.047313035], [359370, 0.04520736], [364986, 0.044975065], [363771, 0.04371042], [364926, 0.043430302], [361836, 0.042960532], [353550, 0.042953826], [360402, 0.04151957], [361547, 0.040312514], [353872, 0.04026328], [357788, 0.03950816], [360400, 0.038518094], [361569, 0.038293824], [354045, 0.035754234], [356617, 0.035465088], [364721, 0.035308458], [360090, 0.03382777], [364976, 0.032558173], [355724, 0.031593926], [362853, 0.031472147], [363284, 0.030951357], [360396, 0.029453313], [353847, 0.029410966], [363160, 0.028991876], [353582, 0.028720502], [352501, 0.028263092], [364036, 0.028077487], [362483, 0.027742228], [354143, 0.027239349], [353494, 0.026978103], [359487, 0.02656035], [357287, 0.026385311], [356183, 0.026066253], [359852, 0.026066253], [363764, 0.025987707], [354810, 0.025921052], [357510, 0.025794268], [358984, 0.025347535], [361299, 0.024846772], [360923, 0.024843467], [359377, 0.023849767], [353556, 0.023511112], [354814, 0.023332452], [364172, 0.023095928], [363168, 0.022908425], [358235, 0.022659399], [363337, 0.022461163], [361011, 0.021918721], [360075, 0.021448879], [360598, 0.02142814], [354449, 0.021326136], [361551, 0.020991286], [364032, 0.019878028], [357101, 0.01985885], [358281, 0.0198082], [361295, 0.019599764], [364332, 0.01944467], [358467, 0.01887471], [356779, 0.018682584], [357447, 0.018629018], [356017, 0.018130865], [359608, 0.018130865], [360600, 0.01726549], [364304, 0.016961131], [358026, 0.016641825], [358471, 0.016608786], [358192, 0.016600547], [354962, 0.016403826], [358001, 0.016353056], [356388, 0.016228933], [360041, 0.016228933], [363276, 0.015974121], [354792, 0.01587027], [360979, 0.015735367], [363338, 0.015722595], [352344, 0.015526015], [355816, 0.015523064], [360294, 0.015402865], [355090, 0.014954733], [355759, 0.014934221], [364311, 0.014679613], [363346, 0.014343945], [357347, 0.014298222], [362725, 0.014120369], [356639, 0.014052985], [354569, 0.013919929], [353072, 0.013556849], [354652, 0.013535033], [356413, 0.013275555], [360069, 0.013275555], [364993, 0.013050809], [363788, 0.012912704], [356966, 0.0128275165], [362723, 0.012407509], [356630, 0.012390814], [362851, 0.012272899], [357526, 0.012152224], [365073, 0.011899565], [354938, 0.0118050575], [364035, 0.011294761], [364447, 0.011187342], [356411, 0.011158578], [360066, 0.011158578], [364633, 0.01088854], [363588, 0.0107972715], [362003, 0.010634766], [352859, 0.010609805], [357498, 0.010596278], [361998, 0.010545647], [364031, 0.010332408], [364452, 0.010208019], [360468, 0.0101740165], [360839, 0.0099317], [352700, 0.0098442035], [361140, 0.009755879], [363906, 0.009688806], [361263, 0.00944185], [360846, 0.009293174], [364724, 0.00924955], [363129, 0.009227889], [354238, 0.009037029], [357871, 0.008928258], [365001, 0.008924057], [352493, 0.008866016], [363124, 0.00882181], [357448, 0.008800238], [359858, 0.008728597], [356188, 0.008728597], [361552, 0.008558642], [354679, 0.008508579], [352343, 0.00844764], [358616, 0.0084023075], [362918, 0.008373993], [360226, 0.008365531], [360991, 0.0083078705], [364333, 0.008238151], [357304, 0.008147116], [361408, 0.008108206], [358621, 0.008079402], [354218, 0.007867664], [354430, 0.007779428], [358736, 0.007762655], [354452, 0.0077248695], [360951, 0.0076080333], [354795, 0.0075878226], [361617, 0.00751345], [356565, 0.0074906214], [359495, 0.007481442], [359143, 0.00745379], [354670, 0.0073893755], [359673, 0.0073353965], [358626, 0.0073145125], [354947, 0.0072674723], [361280, 0.007265556], [362586, 0.0072154733], [361711, 0.007169336], [363751, 0.0071577583], [358432, 0.00713379], [355156, 0.007118702], [364779, 0.0071015167], [359853, 0.0069719874], [356065, 0.006945745], [359668, 0.006945745], [361124, 0.0068443352], [361986, 0.006731563], [359831, 0.0065515493], [357313, 0.006531738], [361018, 0.0064994926], [355196, 0.0064847143], [363755, 0.006271611], [357474, 0.0062659527], [362926, 0.0062084906], [355222, 0.0060986346], [359227, 0.0060640313], [353059, 0.0060432497], [364307, 0.005955135], [360997, 0.0059515457], [362074, 0.005851283], [361262, 0.0057994686], [358248, 0.005787433], [363759, 0.005715031], [364718, 0.0057022185], [364321, 0.005640999], [355364, 0.005620412], [360271, 0.0056096003], [358842, 0.0056012305], [352249, 0.0055766907], [361312, 0.0055247564], [360843, 0.005445557], [356602, 0.0053901197], [364169, 0.0053765294], [354596, 0.005360605], [362461, 0.005306358], [358960, 0.0052616834], [362175, 0.0052568484], [361437, 0.0052307267], [354667, 0.005163095], [362869, 0.005148474], [355734, 0.0051417085], [362171, 0.0050889957], [357092, 0.0050584264], [357103, 0.0050569796], [355429, 0.004972082], [356644, 0.004925777], [359771, 0.0049204556], [356225, 0.0049204556], [359681, 0.0048935143], [364454, 0.00486557], [353065, 0.0048430488], [358228, 0.004836228], [361861, 0.0047716545], [358911, 0.0047685737], [359675, 0.0047386126], [359762, 0.004733659], [356216, 0.004733659], [359220, 0.004727871], [364734, 0.0047187475], [364011, 0.0046860576], [358463, 0.0046638916], [364179, 0.004661577], [361150, 0.004631217], [353399, 0.0045107817], [364994, 0.004503685], [364689, 0.00448556], [357288, 0.0044628493], [352331, 0.0044482783], [360072, 0.0043052444], [358067, 0.0042972206], [363740, 0.0042968863], [363282, 0.0042894194], [362473, 0.0042882995], [359376, 0.0042318786], [361298, 0.0041731545], [356781, 0.0041615563], [361025, 0.0041527404], [357095, 0.0041098767], [355420, 0.0041096443], [353083, 0.0041088364], [363898, 0.0041009067], [357093, 0.004099633], [359382, 0.0040333513], [362891, 0.004017133], [354022, 0.0040043877], [363153, 0.003970936], [361285, 0.003928809], [357128, 0.0039178203], [360562, 0.0039162575], [362220, 0.0038992353], [356410, 0.003894096], [363155, 0.0038450689], [361867, 0.0038421042], [362451, 0.003838607], [357521, 0.0038341389], [358443, 0.0038336979], [361291, 0.003776077], [356632, 0.0037688515], [358568, 0.003727599], [364695, 0.0037209801], [358458, 0.0036955436], [357509, 0.0036814355], [353385, 0.0036508471], [357869, 0.0036354358], [362207, 0.0036262637], [363136, 0.003593647], [354629, 0.0035889323], [358466, 0.0035666332], [362223, 0.0035650185], [356859, 0.0035466447], [360655, 0.0035337312], [362858, 0.0035166745], [354968, 0.0035117], [355775, 0.003510152], [360287, 0.0034500428], [355413, 0.0034275674], [355558, 0.0034094786], [357286, 0.003404196], [359648, 0.0033990957], [361849, 0.0033714415], [362132, 0.0033582393], [353227, 0.0033533575], [359131, 0.0033317204], [358725, 0.00332152], [361442, 0.003319615], [354047, 0.0033156972], [360786, 0.003286272], [361827, 0.0032848325], [357709, 0.003258411], [359247, 0.0032433574], [357870, 0.0032417653], [360391, 0.0032391625], [355384, 0.003230522], [361550, 0.0032287242], [364458, 0.0032248104], [359633, 0.0032151805], [355523, 0.00320707], [357702, 0.0031896846], [359498, 0.0031801353], [364631, 0.0031474226], [360584, 0.0031002436], [353229, 0.0030992888], [359134, 0.0030985242], [363455, 0.0030861178], [357302, 0.0030753713], [358975, 0.0030748465], [363757, 0.0030656152], [358455, 0.003043166], [358977, 0.003043166], [359483, 0.003043166], [364675, 0.003043166], [360646, 0.003040725], [363130, 0.0030293842], [359603, 0.0030198267], [363896, 0.0030087081], [363328, 0.0029633555], [364703, 0.002960697], [359653, 0.0029261839], [356055, 0.0029261839], [361292, 0.0029151803], [355201, 0.0029026114], [362225, 0.002875552], [354027, 0.0028615324], [363307, 0.0028393082], [355827, 0.0028313163], [354801, 0.002805207], [356749, 0.002801942], [359135, 0.0027762013], [362125, 0.0027745941], [355565, 0.0027628422], [355740, 0.0027444332], [361000, 0.002737503], [358974, 0.002735927], [355395, 0.0027256203], [364728, 0.0027223066], [354603, 0.00272211], [352819, 0.0027207227], [362176, 0.002698384], [355755, 0.0026942613], [364319, 0.0026592189], [364640, 0.0026492872], [356624, 0.0026473184], [358726, 0.0026301176], [361857, 0.0025722831], [355570, 0.0025709022], [354428, 0.002551143], [360563, 0.0025438475], [358480, 0.0025413602], [361261, 0.0025313112], [353586, 0.002515331], [358036, 0.002503461], [357700, 0.0024786026], [356610, 0.0024732538], [357209, 0.0024670442], [355181, 0.0024667142], [363767, 0.0024627177], [364302, 0.0024401601], [353540, 0.002430758], [364603, 0.0024239824], [364182, 0.0024131702], [363918, 0.0023944313], [354942, 0.0023884997], [359854, 0.0023671428], [355347, 0.002350532], [363895, 0.0023446947], [363863, 0.0023445329], [352329, 0.002336715], [358237, 0.002334372], [364460, 0.0023340154], [359607, 0.0023243786], [356016, 0.0023243786], [359654, 0.0023221138], [363147, 0.0023087184], [354256, 0.002295816], [361566, 0.0022895487], [363143, 0.0022470977], [364687, 0.0022468506], [364305, 0.0022421053], [358006, 0.002232949], [355188, 0.002207939], [361863, 0.0022023972], [360249, 0.0021988573], [359856, 0.0021883566], [356186, 0.0021883566], [363900, 0.0021688484], [355091, 0.0021667948], [363905, 0.0021635292], [363753, 0.0021552593], [352692, 0.002149612], [363697, 0.0021462159], [360730, 0.0021067043], [362298, 0.0020931729], [354235, 0.00208296], [359201, 0.0020751215], [357222, 0.0020565523], [354254, 0.002056519], [364109, 0.0020499446], [354246, 0.0020339747], [352704, 0.0020315312], [353835, 0.002017796], [361778, 0.001994744], [355428, 0.0019912622], [358260, 0.0019831783], [358454, 0.0019829075], [363341, 0.0019729985], [357882, 0.0019694553], [363261, 0.0019680762], [356638, 0.0019603297], [358987, 0.0019544202], [360263, 0.0019265935], [362866, 0.0019144372], [360492, 0.0019092398], [354951, 0.0019053139], [357297, 0.0019020125], [358481, 0.0019006885], [359828, 0.0018900279], [356165, 0.0018900279], [358157, 0.0018887141], [364599, 0.0018570088], [363756, 0.0018568151], [357883, 0.0018434584], [364715, 0.0018276515], [355678, 0.0018270158], [355559, 0.0018264741], [364189, 0.0018200584], [352699, 0.0018030651], [357706, 0.0017797964], [364776, 0.0017678307], [362727, 0.0017621784], [352253, 0.0017621288], [362701, 0.0017502002], [355667, 0.001749961], [355780, 0.0017343953], [355808, 0.0017307353], [364705, 0.0017270385], [360989, 0.0017269464], [363467, 0.0017008698], [358046, 0.0016898488], [355193, 0.0016898054], [360516, 0.0016633263], [354431, 0.0016588419], [357493, 0.0016554355], [363754, 0.0016444064], [358459, 0.0016441513], [364470, 0.0016411102], [359389, 0.0016321588], [355152, 0.00162963], [353407, 0.0016254723], [364314, 0.0016174891], [360847, 0.0016151114], [360825, 0.0016131811], [364739, 0.0016066595], [354435, 0.0015983043], [352870, 0.0015802997], [358044, 0.0015738545], [355389, 0.001568704], [357275, 0.0015471169], [358464, 0.0015442381], [355761, 0.0015400185], [362955, 0.0015205281], [362848, 0.0015044494], [359365, 0.0014919775], [352874, 0.0014760055], [358846, 0.0014713395], [352816, 0.0014677262], [359222, 0.0014646706], [353213, 0.0014630626], [363322, 0.0014616728], [358233, 0.0014571215], [359491, 0.0014360524], [359385, 0.0014358595], [356386, 0.0014330046], [360039, 0.0014330046], [364612, 0.0014326717], [359477, 0.0014224389], [355183, 0.0014077773], [354443, 0.0013929132], [356372, 0.0013880216], [360018, 0.0013880216], [353172, 0.0013789705], [356052, 0.001378266], [359650, 0.001378266], [357079, 0.0013746094], [359536, 0.0013715985], [357490, 0.0013713026], [360789, 0.0013563256], [362144, 0.0013517278], [357488, 0.001338704], [354930, 0.0013336004], [362468, 0.0013316302], [357107, 0.0013026784], [358232, 0.0012937093], [362733, 0.0012917867], [352302, 0.0012655973], [359255, 0.001265023], [353549, 0.0012644262], [358172, 0.0012571483], [364167, 0.0012571483], [363712, 0.0012438187], [356790, 0.0012426014], [364983, 0.0012352584], [363345, 0.0012349613], [355563, 0.0012184329], [355793, 0.0012168521], [360053, 0.0012145523], [356399, 0.0012145523], [356569, 0.0012097182], [364495, 0.0012036992], [354263, 0.0011951854], [355794, 0.001188656], [352683, 0.0011861009], [360954, 0.0011797172], [357670, 0.0011779576], [361835, 0.0011765626], [359925, 0.0011722316], [356288, 0.0011722316], [360833, 0.0011717315], [357319, 0.0011686332], [360269, 0.0011647313], [355673, 0.0011618243], [354177, 0.0011515717], [358983, 0.0011470694], [356594, 0.0011438603], [352494, 0.0011356578], [354939, 0.0011341501], [354258, 0.0011320729], [363682, 0.0011275832], [354804, 0.0011209591], [357455, 0.0010941775], [353376, 0.0010925881], [358195, 0.0010786554], [364995, 0.0010780185], [362002, 0.00104957], [363121, 0.0010464755], [364176, 0.0010463538], [355382, 0.0010432926], [358431, 0.0010422072], [353578, 0.0010339397], [353823, 0.0010234831], [354447, 0.001022661], [356959, 0.000993466], [356614, 0.0009856602], [353201, 0.0009846963], [356484, 0.0009846911], [360147, 0.0009846911], [355776, 0.00097319094], [363167, 0.0009724086], [353825, 0.0009581489], [354421, 0.0009574148], [357233, 0.0009571142], [360998, 0.0009568202], [358453, 0.0009566247], [361685, 0.0009562247], [354606, 0.0009531762], [355909, 0.00095150527], [361545, 0.0009510326], [354780, 0.00094526913], [355212, 0.0009431365], [358410, 0.00094223843], [360575, 0.0009384844], [359469, 0.0009256442], [362301, 0.0009235541], [357705, 0.000919821], [358833, 0.00091784284], [356608, 0.0009109926], [362450, 0.00090932625], [362131, 0.00090785074], [352670, 0.00089501374], [359860, 0.00089456025], [355458, 0.00089334045], [356409, 0.00089223456], [360064, 0.00089223456], [362480, 0.0008857783], [358066, 0.00087704946], [363696, 0.0008749327], [352309, 0.0008742602], [354668, 0.000864084], [357682, 0.00084737997], [353178, 0.0008442047], [355431, 0.0008437631], [353041, 0.00084293017], [355146, 0.00083859847], [360254, 0.0008385345], [355672, 0.00082552695], [358040, 0.00082293706], [359270, 0.0008229206], [358059, 0.0008228202], [357089, 0.00082166295], [363034, 0.00081314804], [356420, 0.00081062835], [360077, 0.00081062835], [361141, 0.00081024907], [356742, 0.0008044975], [358037, 0.00080419704], [355171, 0.00079552335], [357094, 0.0007955116], [360591, 0.0007934803], [363902, 0.00078803237], [364999, 0.0007869626], [361313, 0.00078590674], [355884, 0.0007844813], [361146, 0.0007825915], [361851, 0.0007806762], [364045, 0.0007802355], [354820, 0.00078022137], [356771, 0.00077844464], [362230, 0.0007746993], [364484, 0.00076769904], [363453, 0.00076436345], [354959, 0.00076304906], [358602, 0.0007626405], [357100, 0.0007488892], [353545, 0.0007483153], [357482, 0.0007421326], [358622, 0.00074213225], [359116, 0.0007415649], [354967, 0.0007395504], [361705, 0.00073783944], [357885, 0.00073625805], [361137, 0.0007352865], [360849, 0.0007321059], [355418, 0.00072943553], [363441, 0.00072886574], [353047, 0.0007270859], [360281, 0.0007261245], [361989, 0.00072443456], [358064, 0.00072442385], [363476, 0.0007233884], [357068, 0.0007180157], [354616, 0.00071622286], [363459, 0.0007143605], [360232, 0.0007097637], [354470, 0.0007072284], [357471, 0.0007059745], [359142, 0.0007042583], [354453, 0.00070294336], [355751, 0.0007022116], [352507, 0.0007006707], [360065, 0.0006999289], [354413, 0.00069702993], [352522, 0.00069395156], [357077, 0.000693051], [363569, 0.00069235626], [363446, 0.0006883643], [364678, 0.00068505283], [361860, 0.00068340794], [354261, 0.000682905], [357291, 0.0006803958], [352497, 0.0006685354], [362929, 0.0006657014], [364788, 0.0006656687], [353589, 0.0006616284], [357115, 0.00065843534], [352332, 0.0006532927], [355555, 0.00065066887], [363774, 0.00064762967], [362147, 0.0006475192], [357441, 0.0006475047], [355166, 0.0006444299], [360230, 0.000642087], [363763, 0.0006408246], [358421, 0.0006341669], [355549, 0.0006337352], [357887, 0.00063142396], [358769, 0.0006304916], [357527, 0.00062592566], [357715, 0.00062572706], [357324, 0.00062572677], [357064, 0.0006205527], [354054, 0.0006136959], [360567, 0.0006122855], [358193, 0.0006095753], [360293, 0.00060957245], [360513, 0.00060638075], [357091, 0.00059978623], [360034, 0.0005962885], [357119, 0.00059140107], [358604, 0.000589848], [360082, 0.00058903673], [354613, 0.00058864104], [356305, 0.0005876329], [359947, 0.0005876329], [359674, 0.0005861927], [362155, 0.00058528467], [359130, 0.00058520713], [360062, 0.00058488455], [356407, 0.00058488455], [353860, 0.0005807545], [363102, 0.0005736929], [357688, 0.0005686485], [364670, 0.0005661438], [361565, 0.0005638215], [360645, 0.00056339306], [358819, 0.0005609131], [361128, 0.0005597675], [353592, 0.0005585103], [355426, 0.00055805506], [364163, 0.000557907], [363154, 0.00055664516], [358451, 0.0005555128], [356044, 0.00055473234], [359639, 0.00055473234], [364315, 0.0005546895], [356792, 0.0005488377], [362872, 0.00054725935], [357322, 0.0005444114], [363480, 0.00053740566], [356745, 0.00053713913], [360233, 0.0005352367], [358740, 0.0005316779], [357237, 0.0005292496], [358592, 0.00052900176], [357466, 0.0005278949], [359084, 0.00052735925], [362101, 0.00052683527], [360594, 0.0005219762], [357478, 0.00051959377], [353560, 0.00051959377], [353888, 0.00051944645], [353571, 0.0005188272], [364467, 0.000516753], [353579, 0.00051533984], [358197, 0.0005080325], [363145, 0.0005059526], [353403, 0.00050566765], [352503, 0.00050508935], [355540, 0.00049884914], [361559, 0.00049836433], [361166, 0.0004957932], [354807, 0.0004944915], [354836, 0.0004942693], [364015, 0.0004929747], [358479, 0.0004926733], [355770, 0.00049151946], [358981, 0.00048967224], [359782, 0.0004893505], [356246, 0.0004893505], [362246, 0.00048909103], [360251, 0.00048806015], [362859, 0.0004876226], [353198, 0.00048284628], [353851, 0.00047831004], [354826, 0.00047439846], [353209, 0.0004732783], [355737, 0.00047232828], [356403, 0.0004717901], [360058, 0.0004717901], [358258, 0.00046419157], [356304, 0.0004625086], [359946, 0.0004625086], [353043, 0.0004556207], [360597, 0.00045340112], [361463, 0.0004510393], [356784, 0.00045057814], [355411, 0.00044809558], [361024, 0.00044762404], [361999, 0.0004460436], [363149, 0.0004460123], [354818, 0.0004446704], [360282, 0.00044348976], [358227, 0.00044324758], [356736, 0.00044303574], [364020, 0.00044292826], [359400, 0.00044054768], [364303, 0.00043982553], [364775, 0.00043534144], [355677, 0.00043260778], [364323, 0.0004294147], [353558, 0.000428979], [353200, 0.00042753786], [359784, 0.00042599888], [356248, 0.00042599888], [360521, 0.00042495466], [353865, 0.00042397992], [364320, 0.00042340215], [356606, 0.00042236992], [361576, 0.00042027465], [354604, 0.0004198904], [354260, 0.00041980133], [355417, 0.0004192742], [361692, 0.00041883002], [359954, 0.00041673417], [356311, 0.00041673417], [357112, 0.00041655006], [359950, 0.0004124103], [354223, 0.00041209804], [356612, 0.00040909767], [358030, 0.0004086592], [354618, 0.00040787435], [357519, 0.00040754981], [359945, 0.00040745482], [356303, 0.00040745482], [354970, 0.00040740918], [358693, 0.00040599718], [359656, 0.00040443966], [356941, 0.00040354038], [354819, 0.00039955636], [357314, 0.00039903127], [357567, 0.00039710975], [355557, 0.0003953339], [354229, 0.000393987], [353033, 0.00039224088], [364455, 0.0003919349], [364135, 0.00038664482], [357081, 0.00038610096], [355501, 0.00038361072], [364493, 0.00038156682], [361575, 0.00038111277], [361129, 0.0003806032], [353366, 0.00038035837], [362458, 0.00037799994], [363773, 0.00037746213], [354759, 0.0003749275], [352696, 0.0003741573], [364778, 0.00037363655], [354048, 0.00037349836], [363020, 0.0003724434], [360286, 0.0003696809], [359841, 0.00036879876], [356173, 0.00036879876], [353561, 0.00036715597], [357259, 0.0003665941], [359481, 0.0003658578], [352857, 0.00036482664], [359468, 0.0003645508], [358989, 0.00036391415], [356179, 0.00036357273], [359848, 0.00036357273], [358214, 0.00036137743], [352476, 0.00035982064], [364318, 0.00035686346], [354013, 0.00035659462], [362154, 0.00035644203], [355769, 0.00035621118], [362855, 0.00035582902], [354607, 0.00035378276], [354756, 0.00035276116], [356119, 0.00035276116], [359731, 0.00035276116], [357668, 0.00035258444], [357874, 0.0003519697], [361706, 0.00035166164], [357497, 0.0003514545], [356037, 0.00034898997], [358276, 0.00034724252], [352685, 0.0003457931], [362472, 0.00034452163], [362486, 0.00034308815], [362934, 0.00034153624], [353234, 0.0003401014], [352254, 0.00033588815], [355221, 0.0003343532], [354630, 0.00033398203], [353248, 0.00033375443], [364148, 0.00033316537], [356605, 0.0003328863], [355567, 0.00033075636], [358470, 0.00032780797], [355901, 0.00032758617], [356629, 0.00032389318], [360855, 0.00032269146], [360288, 0.0003225069], [354778, 0.0003217321], [362174, 0.0003209913], [360590, 0.00032004828], [361234, 0.00031989117], [352316, 0.00031908613], [354211, 0.00031825432], [353077, 0.0003167345], [355806, 0.00031303513], [356421, 0.0003130044], [360078, 0.0003130044], [360566, 0.00031266292], [355542, 0.00031073697], [358442, 0.00031028525], [357484, 0.00031022166], [363320, 0.0003099482], [360592, 0.00030957285], [358282, 0.00030691185], [364200, 0.00030691185], [357066, 0.0003061999], [358993, 0.00030553996], [358239, 0.00030438628], [354675, 0.0003030936], [352337, 0.00030192063], [361436, 0.0003017103], [354950, 0.00030082336], [362136, 0.0003004155], [360577, 0.00030040235], [355397, 0.00029822305], [360820, 0.0002976646], [354673, 0.0002972021], [360231, 0.00029715052], [353233, 0.00029600482], [362296, 0.00029565196], [356953, 0.00029266102], [357274, 0.0002915607], [355757, 0.0002889145], [359494, 0.00028834902], [364309, 0.00028696132], [362153, 0.0002858159], [353388, 0.0002848442], [362479, 0.00028296598], [363158, 0.0002801725], [364038, 0.00027985242], [355203, 0.0002782171], [356918, 0.00027768154], [359642, 0.00027630513], [356045, 0.00027630513], [358256, 0.00027502255], [364044, 0.00027483594], [360654, 0.00027420174], [352886, 0.00027373212], [361290, 0.0002716315], [363478, 0.00027149555], [352865, 0.00027124278], [353074, 0.00027097837], [354824, 0.00027053617], [359339, 0.0002694514], [364767, 0.0002685814], [357712, 0.00026840172], [358242, 0.0002683022], [358624, 0.00026591468], [361456, 0.00026508796], [363319, 0.00026414794], [356774, 0.00026377194], [352508, 0.0002636138], [362824, 0.00026331437], [352691, 0.00026286964], [354061, 0.00026249723], [358223, 0.00026198017], [360596, 0.00026135545], [361698, 0.0002601951], [355404, 0.00025992683], [357223, 0.00025842863], [361160, 0.00025634983], [361589, 0.0002563078], [362242, 0.0002563078], [363780, 0.0002535385], [360648, 0.00025317667], [355521, 0.00025246557], [357221, 0.0002506313], [356911, 0.00024920853], [355545, 0.00024902634], [352480, 0.0002485472], [355123, 0.00024827174], [359737, 0.0002463235], [356140, 0.0002463235], [357124, 0.00024604323], [364963, 0.00024602798], [357290, 0.00024563022], [358280, 0.00024496953], [354245, 0.00024432017], [356180, 0.00024362927], [359849, 0.00024362927], [355813, 0.00024113437], [352305, 0.00024069038], [352557, 0.00024034272], [363036, 0.00023828735], [360609, 0.00023658448], [353045, 0.00023456594], [352342, 0.00023389932], [362208, 0.00023347998], [354619, 0.00023291702], [364006, 0.00023078888], [364299, 0.00023009918], [364666, 0.00023009918], [352651, 0.00022990468], [354049, 0.00022872444], [360395, 0.00022770371], [364047, 0.00022566064], [358569, 0.00022429485], [355756, 0.00022426964], [357656, 0.00022363033], [361302, 0.0002220011], [358834, 0.00022190523], [353848, 0.00022170242], [353868, 0.00022039485], [361012, 0.0002176905], [361269, 0.00021696318], [357628, 0.00021688436], [358033, 0.00021595621], [357888, 0.0002158356], [352484, 0.00021459063], [364669, 0.00021380375], [352680, 0.00021358044], [358264, 0.00021324409], [360572, 0.00021236023], [354658, 0.00021233171], [355787, 0.00021133474], [354813, 0.00021027208], [363590, 0.00021011516], [353056, 0.0002096335], [353416, 0.00020796557], [359863, 0.00020763765], [356189, 0.00020763765], [362241, 0.00020627411], [354628, 0.00020538314], [352876, 0.00020424579], [361277, 0.00020355445], [361845, 0.00020355445], [360593, 0.00020350594], [358456, 0.00020277592], [361843, 0.00020084516], [359819, 0.00020069489], [356156, 0.00020069489], [356734, 0.00020069489], [362736, 0.00019998639], [354662, 0.00019946136], [364030, 0.00019894815], [364480, 0.00019890547], [362734, 0.00019812355], [363032, 0.00019780248], [364468, 0.0001965187], [354044, 0.00019596428], [356756, 0.00019463657], [352465, 0.00019440065], [353855, 0.00019276474], [363571, 0.00019160206], [359361, 0.00019155783], [358600, 0.00019141652], [353030, 0.00019141525], [355361, 0.00019141525], [356033, 0.00019141525], [359625, 0.00019141525], [364295, 0.00019122589], [358268, 0.00019079425], [361158, 0.00018915892], [355899, 0.00018742659], [360576, 0.00018731778], [363862, 0.00018717068], [357116, 0.00018585344], [355362, 0.00018559629], [357699, 0.0001853169], [355379, 0.00018504004], [363146, 0.00018498923], [356783, 0.00018415909], [352470, 0.00018363287], [360582, 0.00018346416], [357502, 0.00018314066], [360604, 0.00018283409], [362823, 0.00018167584], [354234, 0.00018158872], [354015, 0.00018149457], [357858, 0.00018121494], [362151, 0.00018055127], [354622, 0.00018038729], [353032, 0.00018036494], [359941, 0.00018018033], [356300, 0.00018018033], [361690, 0.00017974654], [352298, 0.00017931772], [355566, 0.00017895168], [357849, 0.00017894484], [360029, 0.00017883602], [353405, 0.00017823986], [363746, 0.00017642573], [364702, 0.00017638838], [352871, 0.00017579636], [354415, 0.00017576417], [354609, 0.000174845], [361828, 0.00017216905], [361432, 0.00017120288], [361707, 0.00017045213], [356753, 0.0001700659], [360649, 0.00016996897], [357058, 0.00016962411], [362463, 0.00016945276], [364041, 0.00016930547], [355178, 0.00016901287], [358841, 0.00016684532], [354661, 0.00016591407], [357294, 0.0001653356], [361848, 0.00016480769], [358444, 0.00016442593], [363161, 0.00016397299], [364706, 0.00016397299], [355791, 0.00016382452], [357278, 0.0001635765], [355386, 0.0001635595], [357261, 0.00016266364], [358178, 0.00016227001], [361133, 0.00016227001], [361710, 0.00016216669], [354595, 0.00016191685], [354459, 0.00016093712], [359223, 0.00015960695], [363023, 0.00015941577], [358331, 0.00015934723], [364253, 0.00015934723], [356890, 0.00015921873], [355716, 0.00015897799], [357485, 0.00015819528], [361715, 0.0001579585], [357106, 0.0001576577], [352654, 0.000157589], [357893, 0.00015753161], [356050, 0.00015708942], [359647, 0.00015708942], [360651, 0.00015591425], [364667, 0.0001554849], [363289, 0.00015528458], [364048, 0.00015519546], [352280, 0.00015488561], [364592, 0.00015477873], [363684, 0.00015436574], [358213, 0.00015345012], [361856, 0.00015231351], [352472, 0.00015143535], [359636, 0.00015133386], [358452, 0.00015084504], [357321, 0.00014995632], [356763, 0.00014995632], [358212, 0.00014995632], [360558, 0.00014753077], [352320, 0.00014683956], [364753, 0.00014657574], [358828, 0.00014651172], [364978, 0.00014630429], [357701, 0.00014628071], [355519, 0.00014574525], [359260, 0.0001447217], [356960, 0.00014449321], [362864, 0.00014434036], [360583, 0.0001439286], [356220, 0.00014371931], [359767, 0.00014371931], [358206, 0.00014271421], [364643, 0.00014262022], [361865, 0.00014261545], [361008, 0.00014243105], [360581, 0.00014238569], [364496, 0.00014217269], [362233, 0.00014113548], [357676, 0.0001398438], [354402, 0.0001398438], [356384, 0.0001398438], [360037, 0.0001398438], [358207, 0.0001398438], [360827, 0.0001398438], [364729, 0.0001398438], [357445, 0.00013942785], [354928, 0.00013936618], [364743, 0.00013861604], [356187, 0.00013820847], [359857, 0.00013820847], [355900, 0.00013811863], [357513, 0.0001370204], [355815, 0.00013696581], [361021, 0.00013622157], [358462, 0.00013571166], [361859, 0.00013557042], [352487, 0.00013515686], [362925, 0.0001349449], [363123, 0.00013483159], [358731, 0.00013451657], [356950, 0.00013435325], [360250, 0.0001343512], [357320, 0.00013422788], [361709, 0.0001340579], [364597, 0.00013305868], [355150, 0.0001329571], [358837, 0.00013293859], [361015, 0.00013202347], [358250, 0.00013135694], [356601, 0.00013113367], [359373, 0.000130934], [357109, 0.00013035112], [363317, 0.00013024191], [365008, 0.00012972666], [356924, 0.00012939976], [354446, 0.00012928531], [356611, 0.00012887592], [361446, 0.00012874413], [360990, 0.00012824802], [359626, 0.00012804836], [356034, 0.00012804836], [355814, 0.00012801941], [362724, 0.00012782741], [364996, 0.00012782741], [359268, 0.00012779915], [364251, 0.00012758667], [364694, 0.00012735183], [360081, 0.0001269326], [356424, 0.0001269326], [355731, 0.00012645974], [359141, 0.00012630345], [358438, 0.00012575148], [364286, 0.00012575148], [360260, 0.00012529509], [356387, 0.00012445146], [360040, 0.00012445146], [352710, 0.00012398395], [355380, 0.00012294146], [355671, 0.000120874996], [358138, 0.000120818986], [363695, 0.00012057131], [356949, 0.000119556615], [356054, 0.0001193171], [359652, 0.0001193171], [359391, 0.00011898898], [361839, 0.00011895846], [363479, 0.000118384174], [360015, 0.00011832594], [356369, 0.00011832594], [359244, 0.00011821958], [361294, 0.0001178703], [358253, 0.00011752126], [355800, 0.000117268835], [361556, 0.00011705823], [357506, 0.000116801566], [362449, 0.00011608006], [352330, 0.00011576978], [364709, 0.000115436094], [354442, 0.0001151866], [361570, 0.00011487366], [357281, 0.00011419957], [362481, 0.00011370657], [363336, 0.000112772745], [364150, 0.00011254286], [361459, 0.00011191445], [362941, 0.000111522204], [360264, 0.000110349385], [354973, 0.000109717], [354417, 0.00010951328], [353359, 0.00010834815], [355917, 0.000108225475], [352492, 0.0001082197], [355915, 0.00010816295], [355522, 0.00010764632], [354669, 0.00010752813], [360049, 0.00010689847], [356395, 0.00010689847], [354612, 0.00010682835], [355204, 0.00010671199], [360812, 0.000106536194], [357295, 0.000106395986], [358298, 0.000105868006], [353861, 0.000105842766], [354821, 0.000105842766], [362914, 0.00010576771], [357457, 0.000105672945], [360588, 0.0001055528], [354220, 0.00010510995], [363131, 0.000104826984], [354448, 0.00010438121], [355147, 0.00010362797], [364184, 0.000103503735], [361577, 0.00010200042], [361006, 0.00010183774], [356599, 0.00010121291], [361266, 0.00010066821], [361296, 0.00010065553], [356214, 0.0001005948], [359759, 0.0001005948], [354853, 0.00010055825], [357661, 9.977112e-05], [359272, 9.9655976e-05], [363584, 9.902951e-05], [364479, 9.8004966e-05], [354007, 9.679681e-05], [358734, 9.641303e-05], [356588, 9.61224e-05], [354625, 9.587578e-05], [361721, 9.5645475e-05], [357507, 9.551825e-05], [364186, 9.4902134e-05], [360559, 9.467707e-05], [353166, 9.4574105e-05], [365009, 9.4518124e-05], [355402, 9.359601e-05], [354935, 9.230821e-05], [363038, 9.2169685e-05], [359263, 9.189122e-05], [360273, 9.189122e-05], [361003, 9.189122e-05], [361450, 9.189122e-05], [362227, 9.189122e-05], [364735, 9.189122e-05], [358850, 9.17241e-05], [361837, 9.163081e-05], [358008, 9.0003254e-05], [355725, 8.981361e-05], [361689, 8.967199e-05], [355895, 8.958788e-05], [361822, 8.9276524e-05], [355434, 8.9118475e-05], [356075, 8.9118475e-05], [359680, 8.9118475e-05], [356642, 8.9118475e-05], [358071, 8.9118475e-05], [363923, 8.9118475e-05], [355556, 8.891662e-05], [359827, 8.881646e-05], [360553, 8.866177e-05], [354847, 8.755667e-05], [358054, 8.733211e-05], [363909, 8.733211e-05], [364898, 8.706951e-05], [357442, 8.699838e-05], [354642, 8.618611e-05], [355527, 8.598113e-05], [361270, 8.53592e-05], [359777, 8.520509e-05], [352307, 8.5009255e-05], [360810, 8.498713e-05], [362800, 8.472277e-05], [363138, 8.4722364e-05], [352866, 8.443541e-05], [356229, 8.443541e-05], [359775, 8.443541e-05], [364693, 8.433473e-05], [357292, 8.340826e-05], [361010, 8.303709e-05], [363752, 8.266033e-05], [352684, 8.255469e-05], [359126, 8.243975e-05], [360387, 8.188192e-05], [352872, 8.1841325e-05], [353220, 8.1820566e-05], [358708, 8.150378e-05], [354401, 8.1024176e-05], [356765, 8.099521e-05], [362005, 8.0884674e-05], [359658, 8.066639e-05], [356058, 8.066639e-05], [361287, 8.0605096e-05], [361855, 8.0605096e-05], [362477, 8.0605096e-05], [363152, 8.0605096e-05], [357693, 8.0258185e-05], [361114, 8.020096e-05], [356195, 8.016633e-05], [364023, 7.9962476e-05], [358970, 7.988184e-05], [357067, 7.9666854e-05], [354958, 7.9389516e-05], [364462, 7.9360754e-05], [365004, 7.927967e-05], [362890, 7.879008e-05], [353568, 7.8290825e-05], [362930, 7.799507e-05], [355179, 7.7912926e-05], [359113, 7.772466e-05], [361976, 7.766442e-05], [352291, 7.758789e-05], [355378, 7.755297e-05], [364316, 7.7290286e-05], [364293, 7.721456e-05], [357862, 7.681357e-05], [355373, 7.671635e-05], [362273, 7.663593e-05], [364012, 7.648239e-05], [363730, 7.600972e-05], [361002, 7.572936e-05], [364165, 7.5687276e-05], [358430, 7.425333e-05], [362285, 7.3937146e-05], [364770, 7.3436975e-05], [353383, 7.300734e-05], [363580, 7.274958e-05], [357458, 7.263215e-05], [362717, 7.2225885e-05], [357905, 7.19396e-05], [353857, 7.185718e-05], [355705, 7.1153154e-05], [354672, 7.108072e-05], [357282, 7.09162e-05], [356068, 7.036758e-05], [353396, 7.026291e-05], [360225, 7.003113e-05], [353247, 6.980497e-05], [361117, 6.933613e-05], [354790, 6.926462e-05], [353890, 6.9061745e-05], [354407, 6.878812e-05], [355679, 6.878812e-05], [356390, 6.878812e-05], [360043, 6.878812e-05], [357069, 6.878812e-05], [358434, 6.878812e-05], [354212, 6.8532245e-05], [358588, 6.8532245e-05], [355773, 6.837708e-05], [358733, 6.7882145e-05], [357841, 6.772548e-05], [360652, 6.762261e-05], [353394, 6.7509856e-05], [359507, 6.747337e-05], [356014, 6.740789e-05], [359605, 6.740789e-05], [361433, 6.737898e-05], [361847, 6.7123154e-05], [359500, 6.6627705e-05], [357090, 6.611094e-05], [357856, 6.581604e-05], [353878, 6.5797474e-05], [356314, 6.5641296e-05], [359959, 6.5641296e-05], [356637, 6.547107e-05], [364278, 6.5426444e-05], [354471, 6.510734e-05], [361996, 6.487079e-05], [360085, 6.467153e-05], [356426, 6.467153e-05], [356795, 6.464705e-05], [363465, 6.436372e-05], [355748, 6.412381e-05], [353843, 6.410883e-05], [364780, 6.3846615e-05], [358063, 6.367436e-05], [357852, 6.319116e-05], [362871, 6.298907e-05], [364475, 6.298907e-05], [354911, 6.284801e-05], [354465, 6.259226e-05], [361574, 6.255145e-05], [359253, 6.22959e-05], [362895, 6.224803e-05], [361581, 6.20853e-05], [361308, 6.1922816e-05], [362152, 6.18658e-05], [358254, 6.185706e-05], [357717, 6.171048e-05], [362928, 6.1583145e-05], [364751, 6.152333e-05], [361720, 6.081931e-05], [354565, 6.040298e-05], [360589, 6.0174905e-05], [354573, 6.0138478e-05], [354262, 6.012196e-05], [358844, 6.0095485e-05], [353231, 5.998172e-05], [361020, 5.9973765e-05], [355215, 5.9672893e-05], [355822, 5.9672893e-05], [356429, 5.9672893e-05], [360088, 5.9672893e-05], [357122, 5.9672893e-05], [359393, 5.94727e-05], [354798, 5.9436807e-05], [358956, 5.943312e-05], [359467, 5.943312e-05], [363439, 5.9158032e-05], [357904, 5.885822e-05], [357658, 5.8778573e-05], [357456, 5.832168e-05], [359362, 5.8217436e-05], [355561, 5.7672652e-05], [363442, 5.668255e-05], [361864, 5.6349054e-05], [359851, 5.6231114e-05], [356182, 5.6231114e-05], [356777, 5.6231114e-05], [360094, 5.6167555e-05], [364717, 5.615143e-05], [359774, 5.6094435e-05], [356228, 5.6094435e-05], [358996, 5.6003253e-05], [364193, 5.5955796e-05], [360279, 5.5804878e-05], [362203, 5.553758e-05], [354423, 5.548713e-05], [355753, 5.534376e-05], [364194, 5.508192e-05], [360610, 5.495364e-05], [358199, 5.4819437e-05], [361580, 5.4499706e-05], [362916, 5.4436183e-05], [360814, 5.371804e-05], [358717, 5.3485717e-05], [364261, 5.3190302e-05], [358709, 5.3155767e-05], [364672, 5.298663e-05], [352880, 5.265418e-05], [363339, 5.2630236e-05], [362219, 5.2559466e-05], [364639, 5.245972e-05], [358610, 5.2211322e-05], [363040, 5.096088e-05], [358300, 5.0545037e-05], [360063, 5.041088e-05], [356408, 5.041088e-05], [361123, 5.0142622e-05], [364201, 4.9968963e-05], [362715, 4.9964678e-05], [354837, 4.990287e-05], [353867, 4.9714206e-05], [356957, 4.970392e-05], [357889, 4.9428112e-05], [357892, 4.9229784e-05], [352858, 4.922528e-05], [359110, 4.8807353e-05], [358269, 4.8665966e-05], [362214, 4.816989e-05], [355729, 4.8123155e-05], [362735, 4.7836318e-05], [362287, 4.774107e-05], [354178, 4.7699385e-05], [360976, 4.7575504e-05], [354633, 4.7477923e-05], [361147, 4.7206544e-05], [364485, 4.716843e-05], [353080, 4.6702626e-05], [355792, 4.6682635e-05], [355548, 4.635869e-05], [362015, 4.6278965e-05], [353205, 4.6173518e-05], [356776, 4.5927198e-05], [364624, 4.5902198e-05], [358482, 4.5432906e-05], [358946, 4.522477e-05], [360661, 4.5150435e-05], [353415, 4.4951605e-05], [356070, 4.485526e-05], [356789, 4.463138e-05], [357341, 4.4287066e-05], [361718, 4.4091536e-05], [355182, 4.3958782e-05], [364203, 4.3941265e-05], [364692, 4.377188e-05], [354239, 4.3497785e-05], [363770, 4.341358e-05], [359837, 4.3360742e-05], [363157, 4.3326436e-05], [354966, 4.3051597e-05], [360955, 4.2428735e-05], [359390, 4.2241812e-05], [354799, 4.2206542e-05], [357866, 4.2115393e-05], [356962, 4.2007574e-05], [362149, 4.1655214e-05], [352693, 4.1610507e-05], [361284, 4.1431773e-05], [361143, 4.1276075e-05], [354226, 4.1254316e-05], [354576, 4.100103e-05], [362478, 4.0967727e-05], [363039, 4.063722e-05], [354828, 4.0371702e-05], [355772, 4.0371702e-05], [353870, 4.0157483e-05], [362243, 4.012682e-05], [355392, 3.9661238e-05], [356418, 3.9348364e-05], [360074, 3.9348364e-05], [357303, 3.9129307e-05], [354643, 3.9129307e-05], [359657, 3.9129307e-05], [356057, 3.9129307e-05], [358048, 3.9129307e-05], [361001, 3.9129307e-05], [362226, 3.9129307e-05], [358061, 3.911905e-05], [355745, 3.908668e-05], [363315, 3.901972e-05], [356589, 3.9015144e-05], [360386, 3.8636925e-05], [361314, 3.852302e-05], [355202, 3.7658992e-05], [353879, 3.748586e-05], [363304, 3.748157e-05], [363886, 3.737713e-05], [363477, 3.6949863e-05], [364008, 3.6575482e-05], [354039, 3.64793e-05], [358723, 3.6379424e-05], [352888, 3.6125977e-05], [364601, 3.6107827e-05], [355388, 3.6042635e-05], [352705, 3.602356e-05], [356120, 3.5977213e-05], [359732, 3.5977213e-05], [358601, 3.5903628e-05], [355375, 3.5891957e-05], [352495, 3.5853605e-05], [360235, 3.5761066e-05], [362860, 3.5605484e-05], [363472, 3.5040157e-05], [358029, 3.4976292e-05], [357695, 3.4975656e-05], [359398, 3.495352e-05], [361273, 3.4741166e-05], [356884, 3.468502e-05], [359340, 3.468502e-05], [363776, 3.460606e-05], [353386, 3.450397e-05], [360653, 3.413047e-05], [353864, 3.3472326e-05], [357489, 3.2859607e-05], [361594, 3.2836895e-05], [357863, 3.274068e-05], [354796, 3.265138e-05], [355741, 3.265138e-05], [358167, 3.265138e-05], [356746, 3.2633852e-05], [353587, 3.256984e-05], [358847, 3.2512893e-05], [364964, 3.2470445e-05], [355525, 3.234398e-05], [360278, 3.2069278e-05], [357850, 3.1817963e-05], [358742, 3.176936e-05], [355546, 3.17146e-05], [356787, 3.163211e-05], [353404, 3.160271e-05], [362469, 3.146702e-05], [357671, 3.0995914e-05], [357848, 3.0696163e-05], [364196, 3.041506e-05], [358835, 3.0338411e-05], [355762, 3.030261e-05], [358593, 3.0241874e-05], [356944, 3.007552e-05], [360406, 2.962869e-05], [354817, 2.9442679e-05], [352877, 2.9324008e-05], [358472, 2.8888728e-05], [361278, 2.8879584e-05], [364478, 2.8699094e-05], [354024, 2.8637554e-05], [364195, 2.8584513e-05], [362142, 2.8559065e-05], [354834, 2.8496517e-05], [355538, 2.8448649e-05], [356600, 2.8309783e-05], [364252, 2.8172322e-05], [358620, 2.7936274e-05], [359269, 2.7803995e-05], [362490, 2.7711083e-05], [360393, 2.7418038e-05], [360854, 2.7343827e-05], [352520, 2.7321465e-05], [352658, 2.711842e-05], [357318, 2.7062331e-05], [354943, 2.703543e-05], [352660, 2.6320591e-05], [364190, 2.6143352e-05], [360409, 2.5788073e-05], [358265, 2.5713416e-05], [353054, 2.563409e-05], [353236, 2.5599229e-05], [356405, 2.5372543e-05], [357084, 2.5372543e-05], [364472, 2.5338037e-05], [359638, 2.5300926e-05], [356043, 2.5300926e-05], [357692, 2.5179683e-05], [357677, 2.5058327e-05], [353541, 2.4728353e-05], [362247, 2.4441686e-05], [358144, 2.3940353e-05], [355424, 2.3894872e-05], [361028, 2.3694889e-05], [360079, 2.3652512e-05], [356422, 2.3652512e-05], [357307, 2.35641e-05], [355789, 2.3449635e-05], [355216, 2.3400042e-05], [360046, 2.3388575e-05], [362284, 2.3226163e-05], [355905, 2.3217992e-05], [357902, 2.3197275e-05], [355812, 2.3177154e-05], [358849, 2.3116296e-05], [359132, 2.3079201e-05], [360401, 2.3079201e-05], [352488, 2.2586139e-05], [354440, 2.2428057e-05], [358220, 2.196884e-05], [353831, 2.1940787e-05], [356307, 2.1781258e-05], [357300, 2.1705408e-05], [355155, 2.1470978e-05], [364312, 2.141609e-05], [355197, 2.1186906e-05], [352686, 2.1153171e-05], [364748, 2.1099944e-05], [357086, 2.1014817e-05], [353241, 2.1014637e-05], [358273, 2.093269e-05], [353075, 2.091168e-05], [358605, 2.083844e-05], [354831, 2.0790741e-05], [355532, 2.0706784e-05], [364488, 2.0686515e-05], [358968, 2.0425616e-05], [354855, 2.0016962e-05], [363583, 1.983176e-05], [354842, 1.9747777e-05], [363128, 1.9371702e-05], [357907, 1.9107003e-05], [353243, 1.8837853e-05], [353885, 1.8837853e-05], [354850, 1.8837853e-05], [355911, 1.8837853e-05], [356313, 1.8837853e-05], [359956, 1.8837853e-05], [356969, 1.8837853e-05], [360556, 1.8627909e-05], [364464, 1.8550829e-05], [358211, 1.8540446e-05], [362850, 1.853677e-05], [354944, 1.847042e-05], [357216, 1.8333974e-05], [353518, 1.8333974e-05], [363914, 1.81715e-05], [359610, 1.7905246e-05], [356018, 1.7905246e-05], [357499, 1.763946e-05], [357475, 1.7366207e-05], [353569, 1.735925e-05], [352312, 1.6700244e-05], [354788, 1.6699478e-05], [363868, 1.6343567e-05], [354432, 1.6331538e-05], [360290, 1.6112868e-05], [361162, 1.5881138e-05], [364961, 1.5818621e-05], [361152, 1.5818574e-05], [362953, 1.574184e-05], [363288, 1.5725367e-05], [356316, 1.5555745e-05], [359961, 1.5555745e-05], [356932, 1.5480877e-05], [358222, 1.5447828e-05], [361136, 1.5404075e-05], [364191, 1.5352249e-05], [363137, 1.5330976e-05], [357817, 1.5279904e-05], [361826, 1.51064405e-05], [353875, 1.4903236e-05], [353051, 1.4706759e-05], [362947, 1.4534258e-05], [360985, 1.4477139e-05], [357468, 1.4450918e-05], [364610, 1.4450918e-05], [364977, 1.443143e-05], [359506, 1.4201274e-05], [356951, 1.4042748e-05], [361286, 1.3945073e-05], [354040, 1.3940725e-05], [359369, 1.3639213e-05], [361144, 1.3348496e-05], [357897, 1.3168284e-05], [360529, 1.3161693e-05], [357525, 1.2990591e-05], [358836, 1.2764118e-05], [359371, 1.274648e-05], [358216, 1.2513266e-05], [357327, 1.2336868e-05], [358980, 1.2320631e-05], [359488, 1.2320631e-05], [352715, 1.2072622e-05], [356221, 1.1901823e-05], [359768, 1.1901823e-05], [352301, 1.1846742e-05], [354971, 1.1773646e-05], [354854, 1.1551675e-05], [356968, 1.1423074e-05], [356245, 1.1065189e-05], [359781, 1.1065189e-05], [355916, 1.0964828e-05], [356315, 1.0964828e-05], [359960, 1.0964828e-05], [354978, 1.0955191e-05], [363866, 1.0924904e-05], [356757, 1.0784752e-05], [357285, 1.0691064e-05], [352282, 1.0391766e-05], [362245, 9.401368e-06], [364686, 9.193726e-06], [356634, 8.894659e-06], [363916, 8.84806e-06], [360842, 8.212511e-06], [360388, 7.98391e-06], [361854, 7.926517e-06], [358034, 7.911949e-06], [356306, 7.815717e-06], [361306, 7.806205e-06], [361445, 7.803234e-06], [359121, 7.700294e-06], [353833, 7.691488e-06], [364022, 7.5291814e-06], [361431, 7.5099415e-06], [358808, 7.3669767e-06], [362952, 7.3105953e-06], [362470, 7.2250527e-06], [364289, 7.222476e-06], [354014, 7.1822055e-06], [357861, 7.1727186e-06], [354468, 7.151347e-06], [360292, 7.0748697e-06], [357262, 7.0620154e-06], [361592, 7.005809e-06], [356752, 6.9778434e-06], [353596, 6.7124997e-06], [356773, 6.272609e-06], [354663, 6.1376622e-06], [361460, 6.1343094e-06], [361866, 5.4805855e-06], [355376, 4.633254e-06], [364722, 4.6235427e-06], [355134, 4.582101e-06], [360011, 4.536036e-06], [358625, 4.0517793e-06], [361282, 3.0810177e-06], [355168, 1.9569618e-06], [352558, 1.479e-06]]\n",
            "3850\n",
            "3850\n"
          ]
        }
      ],
      "source": [
        "# Predict probability\n",
        "output = []\n",
        "\n",
        "# for i, _x in enumerate(random_search.predict_proba(test)):\n",
        "for i, _x in enumerate(xgbModel.predict_proba(test_set)):\n",
        "    output.append([test_keys.iloc[i].item(), _x[1]])\n",
        "output = sorted(output, reverse=True, key= lambda s: s[1])\n",
        "print(output)\n",
        "\n",
        "# 考慮private alert key部分，滿足上傳條件\n",
        "public_private_alert_key = sample_output['alert_key'].values\n",
        "print(len(public_private_alert_key))\n",
        "\n",
        "# For alert key not in public, add zeros\n",
        "for key in public_private_alert_key:\n",
        "  # print(key)\n",
        "  if key not in test_keys['alert_key'].to_numpy():\n",
        "    output.append([key, 0])\n",
        "\n",
        "print(len(output))\n",
        "\n",
        "predict_alert_key, predict_probability = [], []\n",
        "for key, prob in output:\n",
        "  predict_alert_key.append(key)\n",
        "  predict_probability.append(prob)\n",
        "\n",
        "df_predicted = pd.DataFrame({\n",
        "    \"alert_key\": predict_alert_key,\n",
        "    \"probability\": predict_probability\n",
        "})\n",
        "\n",
        "df_predicted.to_csv('prediction_baseline.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "usz778TT95E6"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
